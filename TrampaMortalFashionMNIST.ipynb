{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0290cf",
   "metadata": {},
   "source": [
    "# Fashion MNIST Model Training & Prediction\n",
    "\n",
    "This notebook trains a neural network on the Fashion MNIST dataset and uses it to predict clothing types from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4bef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: c:\\Users\\Miguel\\Desktop\\Miguelon\\GH\\Machine_Learning_Projects\n",
      "files (top-level): ['.git', '.venv', 'Artificial_Brain_Fashion.ipynb', 'Camino_Del_Guerrero_No_Numpy.ipynb', 'Camino_Del_Guerrero_Numpy.ipynb', 'Conv_MaxPooling2D.ipynb', 'First_Neural_Network_OR_Gate.py', 'Hello.py', 'Neural_Network_AND_Gate.py', 'TrampaMortalFashionMNIST.ipynb', 'zapato_mike.png']\n",
      "Loading Fashion MNIST dataset...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel\\Desktop\\Miguelon\\GH\\Machine_Learning_Projects\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Training data shape: (60000, 28, 28, 1)\n",
      "Test data shape: (10000, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel\\Desktop\\Miguelon\\GH\\Machine_Learning_Projects\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.6952 - loss: 0.8374 - val_accuracy: 0.8145 - val_loss: 0.4806\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.8044 - loss: 0.5361 - val_accuracy: 0.8547 - val_loss: 0.3906\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8358 - loss: 0.4587 - val_accuracy: 0.8635 - val_loss: 0.3643\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8534 - loss: 0.4166 - val_accuracy: 0.8733 - val_loss: 0.3353\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.8660 - loss: 0.3795 - val_accuracy: 0.8835 - val_loss: 0.3107\n",
      "\n",
      "Test accuracy: 88.19%\n",
      "Model saved as: mi_modelo.keras\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import h5py\n",
    "import zipfile\n",
    "\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"files (top-level):\", os.listdir('.'))\n",
    "\n",
    "# Load Fashion MNIST dataset\n",
    "print(\"Loading Fashion MNIST dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize and reshape data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"\\nTraining model...\")\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Save the model\n",
    "model_path = 'mi_modelo.keras'\n",
    "model.save(model_path)\n",
    "print(f\"Model saved as: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03172381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully from: mi_modelo.keras\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "print(\"Loading model...\")\n",
    "model_path = 'mi_modelo.keras'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model = tf.keras.models.load_model(model_path, compile=False)\n",
    "    print(f\"Model loaded successfully from: {model_path}\")\n",
    "else:\n",
    "    print(f\"Error: {model_path} not found. Run the training cell first!\")\n",
    "    model = None\n",
    "\n",
    "def predecir_ropa(ruta_imagen):\n",
    "    \"\"\"Predict clothing type from an image.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError('Model is not loaded. Please run the training cell first.')\n",
    "    \n",
    "    # Preprocess image to match training: grayscale, invert, resize, normalize, batch\n",
    "    img = Image.open(ruta_imagen).convert('L')\n",
    "    img = ImageOps.invert(img)\n",
    "    img = img.resize((28, 28))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = img_array.reshape(1, 28, 28, 1)\n",
    "\n",
    "    # Predict\n",
    "    preds = model.predict(img_array, verbose=0)\n",
    "    probs = np.asarray(preds)[0]\n",
    "\n",
    "    clases = ['Camiseta', 'Pantalón', 'Jersey', 'Vestido', 'Abrigo',\n",
    "              'Sandalia', 'Camisa', 'Zapatilla', 'Bolso', 'Bota']\n",
    "    idx = int(np.argmax(probs))\n",
    "    conf = float(np.max(probs))\n",
    "\n",
    "    print('------------------------------------------------')\n",
    "    print('Imagen:', ruta_imagen)\n",
    "    print('Predicción:', clases[idx].upper())\n",
    "    print('Confianza: {0:.2f}%'.format(conf * 100))\n",
    "    print('Probabilities:', {clases[i]: f\"{probs[i]*100:.1f}%\" for i in range(10)})\n",
    "    print('------------------------------------------------')\n",
    "    return clases[idx], conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4551b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing predictions...\n",
      "------------------------------------------------\n",
      "Imagen: zapato_mike.png\n",
      "Predicción: BOLSO\n",
      "Confianza: 96.45%\n",
      "Probabilities: {'Camiseta': '1.0%', 'Pantalón': '0.5%', 'Jersey': '1.2%', 'Vestido': '0.2%', 'Abrigo': '0.1%', 'Sandalia': '0.3%', 'Camisa': '0.1%', 'Zapatilla': '0.0%', 'Bolso': '96.5%', 'Bota': '0.1%'}\n",
      "------------------------------------------------\n",
      "\n",
      "✓ Successfully predicted: Bolso (confidence: 96.45%)\n"
     ]
    }
   ],
   "source": [
    "# Test the model with the available image\n",
    "print(\"Testing predictions...\")\n",
    "try:\n",
    "    if os.path.exists('zapato_mike.png'):\n",
    "        result, confidence = predecir_ropa('zapato_mike.png')\n",
    "        print(f\"\\n✓ Successfully predicted: {result} (confidence: {confidence*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\"zapato_mike.png not found in current directory\")\n",
    "except Exception as e:\n",
    "    print(f'Error al predecir: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
